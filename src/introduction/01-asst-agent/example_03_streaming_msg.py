"""
Example demonstrating streaming message handling with an AssistantAgent using Azure OpenAI integration.

This script configures an AssistantAgent to stream responses to the console as they are generated.
It authenticates with Azure OpenAI using Azure AD credentials, loads environment variables,
and prints streaming output with optional statistics.

Dependencies:
- autogen_agentchat
- autogen_ext
- azure.identity
-
"""

import asyncio
import os

from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.ui import Console
from autogen_ext.auth.azure import AzureTokenProvider
from autogen_ext.models.openai import AzureOpenAIChatCompletionClient
from azure.identity import DefaultAzureCredential
from dotenv import load_dotenv

load_dotenv()

# Create the token provider
token_provider = AzureTokenProvider(
    DefaultAzureCredential(),
    "https://cognitiveservices.azure.com/.default",
)

model_client = AzureOpenAIChatCompletionClient(
    azure_deployment=os.environ.get("AZURE_OPENAI_API_DEPLOYMENT_NAME"),
    model=os.environ.get("AZURE_OPENAI_API_DEPLOYMENT_NAME"),
    api_version=os.environ.get("AZURE_OPENAI_API_VERSION"),
    azure_endpoint=os.environ.get("AZURE_OPENAI_API_INSTANCE_NAME"),
    azure_ad_token_provider=token_provider,
)

agent = AssistantAgent(
    name="assistant",
    model_client=model_client,
    system_message="Use tools to solve tasks.",
)


async def assistant_run_stream() -> None:
    # Option 1: read each message from the stream (as shown in the previous example).
    # async for message in agent.run_stream(task="Find information on AutoGen"):
    #     print(message)

    # Option 2: use Console to print all messages as they appear.
    await Console(
        agent.run_stream(task="Find information on AutoGen"),
        output_stats=True,  # Enable stats printing.
    )


async def main():
    """
    Asynchronously streams messages from the AssistantAgent and prints them to the console.

    This function uses the Console utility to display messages as they are generated by the agent,
    with optional statistics output. It ensures the model client is properly closed after use.
    """
    await assistant_run_stream()
    await model_client.close()


asyncio.run(main())
